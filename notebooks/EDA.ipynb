{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1m0y3br3vz2"
   },
   "source": [
    "# Exploratory data analysis\n",
    "\n",
    "Классификация: LogR, SVM, NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRAPYX0dLOSh",
    "outputId": "257a7e32-65e3-4079-c973-15f444d015ef"
   },
   "source": [
    "# подключаем облако\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JnvEOOO6z1o"
   },
   "source": [
    "# Информация о наборе данных\n",
    "\n",
    "В качестве датасета используем Rice (Cammeo and Osmancik). (2019). UCI Machine Learning Repository. https://doi.org/10.24432/C5MW4Z.\n",
    "\n",
    "Было сделано 3810 изображений зерен двух сортов риса, после обработки которых получено 7 морфологических признаков зерна:\n",
    "\n",
    "1. Area: площадь - количество пикселей в границах рисового зерна.\n",
    "2. Perimeter: периметр -  расстояние между пикселями вокруг границ рисового зерна.\n",
    "3. Major_Axis_Length: длина по главной оси.\n",
    "4. Minor_Axis_Length: длина по малой оси.\n",
    "5. Eccentricity: эксцентриситет.\n",
    "6. Convex_Area: количество пикселей наименьшей выпуклой оболочки области, образованной рисовым зерном.\n",
    "7. Extent: отношение области, образованной рисовым зерном, к пикселям ограничивающей рамки.\n",
    "8. Class: сорт Османчик и Каммео."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nzPjb8Q0JKSG"
   },
   "source": [
    "# подключим стандартные библиотеки\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6X_1tra71P-"
   },
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "K7KQDUgGLoJ7",
    "outputId": "1c8a134e-c14d-4ccc-ae18-018b3b9a9ba1"
   },
   "source": [
    "df = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/Rice_Dataset_Commeo_and_Osmancik/Rice_Cammeo_Osmancik.xlsx')\n",
    "df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHCYftss3txV"
   },
   "source": [
    "Проверим на наличие пропусков в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bohNhDORvRar",
    "outputId": "a63eb496-7fe1-4a04-bed1-f438c11aa602"
   },
   "source": [
    "df.isna().max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7cB2ZNY8lpf"
   },
   "source": [
    "Проанализируем скатерплот."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "URly2Y_UyVOd",
    "outputId": "bfe5a130-811b-4e1e-9550-626f781d6e4e"
   },
   "source": [
    "sns.pairplot(df, hue = 'Class', diag_kind='hist')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFq3L0hA805j"
   },
   "source": [
    "Явных выбросов нет, длинных правых хвостов также не наблюдаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewc4kcNN9SWF"
   },
   "source": [
    "Разделим наши данные на тренирочные и тестовые в соотношении 4:1. Воспользуемся библиотекой **scikit learn**, которая обладает широкими возможностями и  предоставляет большое количесво алгоритмов и методов для задач машинного обучения. Для равномерного распределения сортов по датасетам добавим параметр `stratify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tk2wAfgvzC0i"
   },
   "source": [
    "from sklearn. model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('Class', axis=1), \n",
    "    df.Class.map(lambda x : 1 if x == 'Cammeo' else 0), # заменим сорт числовым кодом\n",
    "    test_size=1/5, \n",
    "    random_state=4399, \n",
    "    stratify=df.Class\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8t0Eoru5_Fzh"
   },
   "source": [
    "Посмотрим насколько сбалансированы классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wvy_t8cqv6-m",
    "outputId": "87a41433-fed2-4850-eba7-6bfc1b077c05"
   },
   "source": [
    "y_train.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32sPJTet_ub2"
   },
   "source": [
    "Небольшой дисбаланс, пересемлируем малый класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76zx_wyYzRsA",
    "outputId": "341423e2-c966-42c1-c6c1-a5c11e062eee"
   },
   "source": [
    "from sklearn.utils import resample\n",
    "n_samples = y_train.value_counts().max() - y_train.value_counts().min()\n",
    "resampled = resample(X_train.iloc[X_train.index[y_train == 1],:],      \n",
    "                     n_samples=n_samples,\n",
    "                     replace=True,  \n",
    "                     random_state=4399)\n",
    "X_train_resampled = pd.concat([X_train, resampled],\n",
    "                              ignore_index = True)\n",
    "y_train_resampled = y_train.append(pd.Series(1).repeat(n_samples),\n",
    "                                   ignore_index = True)\n",
    "y_train_resampled.value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKvE00BM-W8K"
   },
   "source": [
    "Стандартизуем данные, чтобы нивелировать разный масштаб признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rwOXdAjPzDEQ"
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_resampled), columns = X_train_resampled.columns)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ws62W9VCQ0b-"
   },
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rE8rMWs1IFVt"
   },
   "source": [
    "Сравним модели с разными методами оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MGO_8e-IS7XS",
    "outputId": "f6d778ca-3e77-4687-a8ba-f49d12286637"
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_sag = LogisticRegression(penalty = 'none', # отключение регуляризации\n",
    "                                max_iter = 500, # максимальное число итераций до сходимости\n",
    "                                random_state = 4399, # параметр контроля случайности\n",
    "                                solver = 'sag') # стохастический градиентный спуск в качестве метода оптимизации\n",
    "logreg_sag.fit(X_train_scaled, y_train_resampled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fv6EptdrLTeE",
    "outputId": "a8e50c95-18af-4959-8c38-f38a01ab66f4"
   },
   "source": [
    "logreg_lbfgs = LogisticRegression(penalty = 'none',\n",
    "                                max_iter = 500, \n",
    "                                random_state = 4399,\n",
    "                                solver = 'lbfgs') # алгоритм Бройдена — Флетчера — Гольдфарба — Шанно c ограниченной памятью\n",
    "logreg_lbfgs.fit(X_train_scaled, y_train_resampled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96ad4bw3b-rb"
   },
   "source": [
    "Подготовим функции для подсчета метрик качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vr51RgJ2JZ-K"
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "def quality_report(expected, actual):\n",
    "    print(\"Accuracy: {:.3f}\\nPrecision: {:.3f}\\nRecall: {:.3f}\\nf1_score: {:.3f}\\n\".format(\n",
    "        accuracy_score(expected, actual),  # доля правильно классифицированных объектов\n",
    "        precision_score(expected, actual), # точность\n",
    "        recall_score(expected, actual), # полнота\n",
    "        f1_score(expected, actual) # гармоническое среднее\n",
    "    ))\n",
    "    print(confusion_matrix(expected, actual),'\\n') # матрица неточностей "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCaJ8SsjcOxj"
   },
   "source": [
    "Аналогично для построения ROC кривой.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "FwU1wF7mQG1u"
   },
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "def plot_roc_curve(expected, actual_prob):\n",
    "    fpr, tpr, _ = roc_curve(expected, actual_prob) # доли ложно положительной классификации и верно предсказанных классов\n",
    "    score = roc_auc_score(expected, actual_prob) # площадь под кривой ошибок \n",
    "    plt.plot(fpr, tpr, label='ROC curve ')\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC AUC: {:.5f}'.format(score))\n",
    "    plt.show()\n",
    "    print()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnW7dRyrdD8J"
   },
   "source": [
    "Заготовка функции для вывода результатов классификации на тренировочных и тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "au6hedOCk5j5"
   },
   "source": [
    "def print_results(model):\n",
    "  print(model, \"on TRAIN\")\n",
    "  quality_report(y_train, model.predict(X_train_scaled[:-n_samples]))\n",
    "  plot_roc_curve(y_train, model.predict_proba(X_train_scaled)[:-n_samples,1])\n",
    "  print(model, \"on TEST\")\n",
    "  quality_report(y_test, model.predict(X_test_scaled))\n",
    "  plot_roc_curve(y_test, model.predict_proba(X_test_scaled)[:,1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGv9YKszeZn_"
   },
   "source": [
    "Теперь можем оценить работу обученных выше моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "_K6_pokFozgP",
    "outputId": "73b0b141-b76b-4516-ee58-a6a2ec0ee6d5"
   },
   "source": [
    "print_results(logreg_sag)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y71oFvAceX14"
   },
   "source": [
    "Достаточно высокая точность. Гармоническое среднее и площадь по кривой ошибок близки к единице. Данные хорошо поддаются классификации.\n",
    "\n",
    "Посмотрим, как отработала вторая модель (в качестве метода оптимизации алгоритм Бройдена — Флетчера — Гольдфарба — Шанно c ограниченной памятью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "ptHilnZLozny",
    "outputId": "2b5996b8-da50-4935-e67d-f22e929c8eca"
   },
   "source": [
    "print_results(logreg_lbfgs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubCmBQU5fgwX"
   },
   "source": [
    "В целом разницы практически нет. Переобучения в обоих моделях не выявлено."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zo5FQhrQtYl"
   },
   "source": [
    "# Метод опорных векторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcEEGngMppiz"
   },
   "source": [
    "Сравним модели с линейно разделяющей плоскостью и полиномиальным ядром."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UR3HYpibVAQd",
    "outputId": "e6fa44da-236c-499d-8cb2-6ccb409249df"
   },
   "source": [
    "from sklearn import svm\n",
    "svm_linear = svm.SVC(kernel='linear', # тип ядра, который будет использоваться в алгоритме\n",
    "                     probability=True, # вывод оценки вероятности\n",
    "                     random_state=4399)\n",
    "svm_linear.fit(X_train_scaled, y_train_resampled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "6Cl1Sw31nuI0",
    "outputId": "a9f56d39-88bb-4f9d-ad31-5c9e8cc0fdb7"
   },
   "source": [
    "print_results(svm_linear)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njvkaZ38i7Pw"
   },
   "source": [
    "Метрики выше, чем у логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rsx-dZJ3jDWf"
   },
   "source": [
    "Попробуем полиномиальнео ядро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZDjLadkVf5f",
    "outputId": "e75bee8d-cc12-4d4e-accf-01aabe4f49b5"
   },
   "source": [
    "svm_poly = svm.SVC(kernel='poly', \n",
    "                   degree=3, # cтепень полиномиальной функции ядра \n",
    "                   probability=True)\n",
    "svm_poly.fit(X_train_scaled, y_train_resampled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "id": "iGm61zDdnQfH",
    "outputId": "2a8d8e9c-83ab-4a6a-f01c-23359cea0abc"
   },
   "source": [
    "print_results(svm_poly)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeVmn281jrmK"
   },
   "source": [
    "Число ошибок увеличилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKGP30iCQy-p"
   },
   "source": [
    " # Нейронные сети"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zlGKDAelKYe"
   },
   "source": [
    "Воспользуемся перцептроном `MLPClassifier` из библиотеки *scikit learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ch5_E-OqkPUz"
   },
   "source": [
    "\n",
    "Сначала посмотрим в целом, насколько быстро можно обучиться до приемлемой точности со стандартными параметрами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Z6PDR6TDQzWG"
   },
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(random_state = 4399, \n",
    "                   max_iter=1, # максимальное количество итераций\n",
    "                   warm_start=True) # повторно используем решение предыдущего вызова для инициализации"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tF-n2cGQm0Lg"
   },
   "source": [
    "Отделим от тренировочных данных 20% для валидационной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6B0AXe9fyzRJ"
   },
   "source": [
    "X_subtrain, X_validation, y_subtrain, y_validation = train_test_split(X_train_resampled, y_train_resampled, train_size=4/5, stratify=y_train_resampled)\n",
    "X_subtrain_scaled = pd.DataFrame(scaler.fit_transform(X_subtrain), columns = X_subtrain.columns)\n",
    "X_validation_scaled = pd.DataFrame(scaler.transform(X_validation), columns = X_validation.columns)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y85mboLenVAD"
   },
   "source": [
    "Нарисуем графики accuracy модели на тестовых и валидационных данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "k8Pr-1584FyB",
    "outputId": "c804cc03-1e93-4aaa-9c4e-9dd9c4be2dd8"
   },
   "source": [
    "scores = [(nn.fit(X_subtrain_scaled, y_subtrain).score(X_subtrain_scaled, y_subtrain), nn.score(X_validation_scaled, y_validation)) for _ in range(300)]\n",
    "plt.plot(scores)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pV3DewTGu_-I"
   },
   "source": [
    "Доля правильно классифицированных объектов на валидационной выборке после выхода на плато начинает уменьшаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkU0JaUzoQhU"
   },
   "source": [
    "Будем искать оптимальные параметры по сетке с помощью кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "Y7BnYOU3XqQ6"
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "param_grid = [{'model__hidden_layer_sizes':[(10,),(50,),(100,)], # количество нейронов в скрытом слое\n",
    "               'model__activation': ['logistic', 'relu'], # функция активации для скрытого слоя\n",
    "               'model__learning_rate_init': [0.1, 0.01, 0.001], # начальная скорость обучения\n",
    "               'model__max_iter': [100, 200]}]\n",
    "grid_search = GridSearchCV(estimator=Pipeline([('scaler', scaler), ('model', MLPClassifier(random_state = 4399))]),\n",
    "                           param_grid=param_grid, \n",
    "                           scoring=make_scorer(accuracy_score), # максимизируем долю правильно классифицированных объектов\n",
    "                           n_jobs=-1) # использование всех процессоров"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xw8MbGlBrRfr"
   },
   "source": [
    "Подбираем параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NiNXLg8Xqnw",
    "outputId": "2892d9a8-ada7-42a9-fa14-94f57ee80626"
   },
   "source": [
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "grid_search.best_params_"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhCuwTVSuBlU"
   },
   "source": [
    "Обучаем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "gKE0Q8uJJiVI",
    "outputId": "5d7dec98-ba41-474e-e8df-f0b3b981a2c3"
   },
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(50,), activation = 'logistic', learning_rate_init = 0.1, max_iter = 100, random_state = 4399)\n",
    "nn.fit(X_train_scaled, y_train_resampled)\n",
    "print_results(nn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKPYIYbpYbln"
   },
   "source": [
    "Резкого увеличения количества ошибок на тестовых данных нет. Метрики сопоставимы с методом опорных векторов с линейным ядром. Разница в том, что перцептрон лучше обнаруживает сорт Османчик, а SVM — Каммео. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
